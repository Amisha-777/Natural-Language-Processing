{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684b5855-d8af-4c97-bfec-f10dd98a7138",
   "metadata": {},
   "source": [
    "# Text Clustering with Multiple Algorithms in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "edfb95e6-3c24-4a1a-9ea2-9aedfb11447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms Covered \n",
    "# 1. K-Means Clustering \n",
    "# 2. Hierarchical Clustering (Agglomerative) \n",
    "# 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615aed1-398e-4daa-847b-8791a75c363a",
   "metadata": {},
   "source": [
    "## Task 1: Preprocess the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a089f-e0fe-4608-b3cb-72daeba8168e",
   "metadata": {},
   "source": [
    "### Load Dataset (IMDB Reviews from nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a8f7ce9b-1a42-4c2b-b9cf-05ca6b3ed3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 2000 samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Download Required NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load Dataset (IMDB Reviews Dataset from NLTK)\n",
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')\n",
    "documents = [' '.join(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]\n",
    "df = pd.DataFrame(documents, columns=['text'])\n",
    "print(f\"Dataset loaded successfully with {len(df)} samples.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d33d5-6207-498b-a562-c89771f71404",
   "metadata": {},
   "source": [
    "### Preprocess the Text\n",
    "Preprocessing Steps:\n",
    "Convert text to lowercase.\n",
    "Remove punctuation.\n",
    "Tokenize and remove stop words.\n",
    "Lemmatize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c41fcc0-eb83-47ad-a017-2ae65a7374d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # Remove punctuation\n",
    "    words = nltk.word_tokenize(text)  # Tokenize text\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatize and remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"Text preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afbc72-3acd-47b2-8c50-e8be6d6a1137",
   "metadata": {},
   "source": [
    "## Task 2: Apply TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24335bb2-7126-4ac9-a31e-8b41e3851bcf",
   "metadata": {},
   "source": [
    "### Convert Text into Numerical Features\n",
    "Use TfidfVectorizer from sklearn.feature_extraction.text. Limit the number of features to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a157be9a-0a5f-4b9a-85bf-a709efad1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF transformation completed. Shape: (2000, 5000)\n",
      "\n",
      "Sample TF-IDF Vectorization Result:\n",
      "   000      10  100   11   12   13  13th   14   15   16  ...  younger  \\\n",
      "0  0.0  0.4576  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...      0.0   \n",
      "1  0.0  0.0000  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...      0.0   \n",
      "2  0.0  0.0000  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...      0.0   \n",
      "3  0.0  0.0000  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...      0.0   \n",
      "4  0.0  0.0000  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...      0.0   \n",
      "\n",
      "   youngster  youth  zane  zany  zellweger  zero  zeta  zombie  zone  \n",
      "0        0.0    0.0   0.0   0.0        0.0   0.0   0.0     0.0   0.0  \n",
      "1        0.0    0.0   0.0   0.0        0.0   0.0   0.0     0.0   0.0  \n",
      "2        0.0    0.0   0.0   0.0        0.0   0.0   0.0     0.0   0.0  \n",
      "3        0.0    0.0   0.0   0.0        0.0   0.0   0.0     0.0   0.0  \n",
      "4        0.0    0.0   0.0   0.0        0.0   0.0   0.0     0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert text data into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "print(f\"TF-IDF transformation completed. Shape: {X.shape}\\n\")\n",
    "\n",
    "# Print Sample TF-IDF Features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "sample_tfidf = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "print(\"Sample TF-IDF Vectorization Result:\")\n",
    "print(sample_tfidf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ee144-a622-4599-8f39-af1c48278a33",
   "metadata": {},
   "source": [
    "## Task 3: Implement Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133511a1-49f8-4d42-982c-4bb8ffe7bf26",
   "metadata": {},
   "source": [
    "### Implement K-Means Clustering and Measure Computational Efficiency\n",
    "Weâ€™ll use 5 clusters as an example. Assign cluster labels to each text sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff2cc2bb-512c-4e5a-b73c-90e52e889ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Clustering Completed in 0.0666 seconds.\n",
      "Cluster 0 (K-Means):\n",
      "   - plot : two teen couples go to a church party , drink and then drive . they get into an accident . on...\n",
      "\n",
      "   - it is movies like these that make a jaded movie viewer thankful for the invention of the timex indig...\n",
      "\n",
      "Cluster 1 (K-Means):\n",
      "   - the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie s...\n",
      "\n",
      "   - capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title m...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Means Clustering\n",
    "start_time = time.time()\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['kmeans_cluster'] = kmeans.fit_predict(X)\n",
    "kmeans_time = time.time() - start_time\n",
    "\n",
    "print(f\"K-Means Clustering Completed in {kmeans_time:.4f} seconds.\")\n",
    "\n",
    "# Print K-Means Cluster Assignments\n",
    "for i in range(2):\n",
    "    print(f\"Cluster {i} (K-Means):\")\n",
    "    for text in df[df['kmeans_cluster'] == i]['text'].values[:2]:\n",
    "        print(f\"   - {text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07ed4d-7aaf-4eb2-8b32-7cde42b2f4e7",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "Perform clustering with different linkage methods (ward, average, complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d80aeec7-db9d-4f3f-a0e8-979f8e2a63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering (ward) Completed in 3.2714 seconds.\n",
      "Cluster 0 (Hierarchical - Ward):\n",
      "   - plot : two teen couples go to a church party , drink and then drive . they get into an accident . on...\n",
      "\n",
      "   - the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie s...\n",
      "\n",
      "Cluster 1 (Hierarchical - Ward):\n",
      "   - capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title m...\n",
      "\n",
      "   - john carpenter makes b - movies . always has ( \" halloween , \" \" escape from new york , \" \" the thin...\n",
      "\n",
      "Hierarchical Clustering (average) Completed in 3.3816 seconds.\n",
      "Cluster 0 (Hierarchical - Average):\n",
      "   - plot : two teen couples go to a church party , drink and then drive . they get into an accident . on...\n",
      "\n",
      "   - the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie s...\n",
      "\n",
      "Cluster 1 (Hierarchical - Average):\n",
      "   - the thought - provoking question of tradition over morals is the subject directly at the core of \" l...\n",
      "\n",
      "Hierarchical Clustering (complete) Completed in 3.2609 seconds.\n",
      "Cluster 0 (Hierarchical - Complete):\n",
      "   - plot : two teen couples go to a church party , drink and then drive . they get into an accident . on...\n",
      "\n",
      "   - the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie s...\n",
      "\n",
      "Cluster 1 (Hierarchical - Complete):\n",
      "   - capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title m...\n",
      "\n",
      "   - john carpenter makes b - movies . always has ( \" halloween , \" \" escape from new york , \" \" the thin...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linkages = ['ward', 'average', 'complete']\n",
    "hierarchical_scores = {}\n",
    "\n",
    "for linkage in linkages:\n",
    "    start_time = time.time()\n",
    "    agglo = AgglomerativeClustering(n_clusters=5, linkage=linkage)\n",
    "    df[f'hierarchical_cluster_{linkage}'] = agglo.fit_predict(X.toarray())\n",
    "    hierarchical_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Hierarchical Clustering ({linkage}) Completed in {hierarchical_time:.4f} seconds.\")\n",
    "    \n",
    "    # Print Cluster Assignments\n",
    "    for i in range(2):\n",
    "        print(f\"Cluster {i} (Hierarchical - {linkage.capitalize()}):\")\n",
    "        for text in df[df[f'hierarchical_cluster_{linkage}'] == i]['text'].values[:2]:\n",
    "            print(f\"   - {text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d032dc39-1c41-4e4a-b384-075bd9f98f03",
   "metadata": {},
   "source": [
    "### DBSCAN Clustering\n",
    "Experiment with different eps and min_samples values. Assign cluster labels and observe how DBSCAN handles outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "daed2f6f-c4dd-4d8d-9db4-36b5f754edce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Clustering Completed in 0.6245 seconds.\n",
      "Cluster 0 (DBSCAN):\n",
      "   - the tagline for this film is : \" some houses are just born bad \" . so i didn ' t expect too much fro...\n",
      "\n",
      "   - the tagline for this film is : \" some houses are just born bad \" . so i didn ' t expect too much fro...\n",
      "\n",
      "Cluster 1 (DBSCAN):\n",
      "   - it seemed like the perfect concept . what better for the farrelly brothers , famous for writing and ...\n",
      "\n",
      "   - it seemed like the perfect concept . what better for the farrelly brothers , famous for writing and ...\n",
      "\n",
      "Cluster 2 (DBSCAN):\n",
      "   - i know that \" funnest \" isn ' t a word . \" fun \" is a noun , and therefore cannot be conjugated like...\n",
      "\n",
      "   - i know that \" funnest \" isn ' t a word . \" fun \" is a noun , and therefore cannot be conjugated like...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "dbscan = DBSCAN(eps=1.0, min_samples=2)\n",
    "df['dbscan_cluster'] = dbscan.fit_predict(X_normalized)\n",
    "dbscan_time = time.time() - start_time\n",
    "\n",
    "print(f\"DBSCAN Clustering Completed in {dbscan_time:.4f} seconds.\")\n",
    "\n",
    "# Print DBSCAN Cluster Assignments\n",
    "for i in set(df['dbscan_cluster']):\n",
    "    if i != -1:  # Ignore noise points\n",
    "        print(f\"Cluster {i} (DBSCAN):\")\n",
    "        for text in df[df['dbscan_cluster'] == i]['text'].values[:2]:\n",
    "            print(f\"   - {text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4206ac3-caea-43b7-b4db-1d998de6a4f2",
   "metadata": {},
   "source": [
    "## Task 4: Compare Clustering Results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd897b-63e4-43d1-9d09-b4261986a799",
   "metadata": {},
   "source": [
    "### Evaluate Cluster Quality Using Silhouette Score and Calinski-Harabasz Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3c8e9ac-c8a3-45bf-93a5-abc870703cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Clustering Results:\n",
      "\n",
      " K-Means\n",
      "   - Silhouette: 0.0016380301972095496\n",
      "   - Calinski-Harabasz: 5.849027695192205\n",
      "\n",
      "\n",
      " Hierarchical (ward)\n",
      "   - Silhouette: 0.0032244468066553304\n",
      "   - Calinski-Harabasz: 6.497514279685561\n",
      "\n",
      "\n",
      " Hierarchical (average)\n",
      "   - Silhouette: 0.012599900637509417\n",
      "   - Calinski-Harabasz: 1.0697628484000214\n",
      "\n",
      "\n",
      " Hierarchical (complete)\n",
      "   - Silhouette: 0.001667928968429133\n",
      "   - Calinski-Harabasz: 2.2499728124182945\n",
      "\n",
      "\n",
      " DBSCAN\n",
      "   - Silhouette: 0.9999999900585097\n",
      "   - Calinski-Harabasz: N/A\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# K-Means Evaluation\n",
    "kmeans_score = silhouette_score(X, df['kmeans_cluster'])\n",
    "kmeans_ch_score = calinski_harabasz_score(X.toarray(), df['kmeans_cluster'])\n",
    "results['K-Means'] = {'Silhouette': kmeans_score, 'Calinski-Harabasz': kmeans_ch_score}\n",
    "\n",
    "# Hierarchical Evaluation\n",
    "for linkage in linkages:\n",
    "    hierarchical_score = silhouette_score(X, df[f'hierarchical_cluster_{linkage}'])\n",
    "    hierarchical_ch_score = calinski_harabasz_score(X.toarray(), df[f'hierarchical_cluster_{linkage}'])\n",
    "    results[f'Hierarchical ({linkage})'] = {'Silhouette': hierarchical_score, 'Calinski-Harabasz': hierarchical_ch_score}\n",
    "\n",
    "# DBSCAN Evaluation\n",
    "valid_dbscan_clusters = df[df['dbscan_cluster'] != -1]['dbscan_cluster']\n",
    "if len(set(valid_dbscan_clusters)) > 1:\n",
    "    dbscan_score = silhouette_score(X_normalized[df['dbscan_cluster'] != -1], valid_dbscan_clusters)\n",
    "else:\n",
    "    dbscan_score = 'N/A'\n",
    "\n",
    "results['DBSCAN'] = {'Silhouette': dbscan_score if dbscan_score != 'N/A' else 'N/A', 'Calinski-Harabasz': 'N/A'}\n",
    "\n",
    "# Print Clustering Results\n",
    "print(\"\\n Clustering Results:\\n\")\n",
    "for algo, metrics in results.items():\n",
    "    print(f\" {algo}\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"   - {key}: {value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae992d10-8d85-4697-95c4-b9f8cad3d3a4",
   "metadata": {},
   "source": [
    "## Task 5: Result Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e71e72-33ef-4de8-9a75-72d8a85737c1",
   "metadata": {},
   "source": [
    "### Analysis of algorithms on Cluster quality, Handling noise and outliers, Scalability to larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a71e3f-1703-4f5f-80fc-cfc56fb791dd",
   "metadata": {},
   "source": [
    "##### K-Means Clustering:\n",
    "K-Means is highly efficient and scalable, completing the clustering in just 0.0722 seconds, making it the fastest of all algorithms. However, its cluster quality was poor, with a Silhouette Score of 0.0016 and a Calinski-Harabasz Score of 5.85, indicating poorly defined clusters. Additionally, K-Means is sensitive to outliers and noise, which can significantly affect the results, making it less suitable for noisy datasets.\n",
    "\n",
    "##### Hierarchical Clustering (Ward, Average, Complete):\n",
    "Hierarchical Clustering, while providing a hierarchical view of the data, showed poor cluster quality across all three linkage methods:\n",
    "\n",
    "Ward: Silhouette Score: 0.0032, Calinski-Harabasz Score: 6.50\n",
    "\n",
    "Average: Silhouette Score: 0.0126, Calinski-Harabasz Score: 1.07\n",
    "\n",
    "Complete: Silhouette Score: 0.0017, Calinski-Harabasz Score: 2.25 Hierarchical Clustering was also computationally expensive, taking around 3.15 seconds for each linkage method. It struggles to handle noise and may merge noise points into clusters, making it less effective for datasets with high noise.\n",
    "\n",
    "##### DBSCAN (Density-Based Clustering):\n",
    "DBSCAN produced the highest cluster quality, with a near-perfect Silhouette Score of 0.9999, indicating well-defined clusters. It effectively handled noise and outliers by marking them as noise (-1), which other algorithms failed to manage. DBSCAN was relatively efficient, completing the clustering in 0.5127 seconds, although it is slower than K-Means but faster than Hierarchical Clustering. However, DBSCAN requires careful tuning of the eps and min_samples parameters to achieve optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64c869-cc62-40e5-943f-6eef9060c8d0",
   "metadata": {},
   "source": [
    "### Most suitable algorithm for this dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a46a18-efc8-4353-bf99-a5f0fc368d97",
   "metadata": {},
   "source": [
    "Given the results, DBSCAN is the most suitable algorithm for this dataset. It provided the highest cluster quality and effectively handled noise and outliers, making it ideal for datasets where clusters have irregular shapes or contain noisy data. Unlike K-Means and Hierarchical Clustering, DBSCAN does not require specifying the number of clusters in advance, which adds to its flexibility. Therefore, DBSCAN is recommended as the best clustering algorithm for this dataset, ensuring high cluster quality and robustness to noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
